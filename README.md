# 🎓 Machine Learning Internship Projects (CDAC Noida)

This repository contains three practical Machine Learning projects completed during a hands-on internship. Each project involves real-world datasets and covers data cleaning, visualization, and predictive modeling using Python and Colab.

---

## 📁 Project 1: Instagram Fake, Spammer & Genuine Account Detection

**Objective**: Detect whether an Instagram account is fake, spam, or genuine using profile metadata.

### Key Steps:
- Data loading and preprocessing
- Feature engineering and selection
- Data visualization (histograms, scatterplots, etc.)
- Training ML models for multi-class classification

### Models Used:
- Logistic Regression
- Random Forest
- K-Nearest Neighbors

### Evaluation:
- Accuracy
- Confusion Matrix
- Classification Report

---

## 📁 Project 2: Netflix Dataset – Cleaning, Analysis & Visualization

**Objective**: Explore, clean, and analyze Netflix content metadata to uncover insights about its content catalog.

### Key Steps:
- Data cleaning (handling nulls, type casting)
- Visual analysis using bar plots, heatmaps, and pie charts
- Insights about:
  - Most common genres
  - Country-wise content production
  - Content trends over time
  - Movie vs TV Show distribution

### Tools Used:
- Pandas, NumPy
- Matplotlib, Seaborn

### Outcome:
An interactive and visual exploration of Netflix’s vast media collection.

---

## 📁 Project 3: Unlocking YouTube Channel Performance Secrets

**Objective**: Analyze YouTube channel performance data to uncover factors affecting video success.

### Key Steps:
- Preprocessing engagement metrics like likes, views, comments, etc.
- Visualizing relationships (scatterplots, correlation heatmaps)
- Classifying videos as successful or not based on features
- Predictive modeling to understand engagement drivers

### Models Used:
- Logistic Regression
- Random Forest
- K-Nearest Neighbors

### Evaluation:
- ROC-AUC
- Accuracy
- Confusion Matrix

---

## 🛠️ Tools & Libraries Used
- Google Colab (Jupyter Notebook)
- Python 3
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- Imbalanced-learn (for SMOTE)

---

## 📦 How to Use

You can open each notebook directly in Google Colab.

If running locally, install dependencies:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
